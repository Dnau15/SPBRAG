{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/micromamba/envs/spbrag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from transformers import get_scheduler\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>prompt</th>\n",
       "      <th>need_retrieval</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>closed_qa</td>\n",
       "      <td>When did Virgin Australia start operating? Vir...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classification</td>\n",
       "      <td>Which is a species of fish? Tope or Rope</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>open_qa</td>\n",
       "      <td>Why can camels survive for long without water?</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open_qa</td>\n",
       "      <td>Alice's parents have three daughters: Amy, Jes...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>closed_qa</td>\n",
       "      <td>When was Tomoaki Komorida born? Komorida was b...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                             prompt  \\\n",
       "0       closed_qa  When did Virgin Australia start operating? Vir...   \n",
       "1  classification          Which is a species of fish? Tope or Rope    \n",
       "2         open_qa    Why can camels survive for long without water?    \n",
       "3         open_qa  Alice's parents have three daughters: Amy, Jes...   \n",
       "4       closed_qa  When was Tomoaki Komorida born? Komorida was b...   \n",
       "\n",
       "   need_retrieval title context answers  \n",
       "0               0   NaN     NaN     NaN  \n",
       "1               0   NaN     NaN     NaN  \n",
       "2               1   NaN     NaN     NaN  \n",
       "3               1   NaN     NaN     NaN  \n",
       "4               0   NaN     NaN     NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/merged.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is imbalanced, meaning some classes have significantly more examples than others. \\\n",
    "To address this and ensure fair representation, I decided to use a balanced subset of the data. \\\n",
    "Specifically, I limited the dataset to 1,500 examples per class. \\\n",
    "This approach helps prevent the model from being biased toward the majority class while still providing enough data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13353/3581472250.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(num_samples_per_class, random_state=42), include_groups=True)\n"
     ]
    }
   ],
   "source": [
    "num_samples_per_class = 1000\n",
    "balanced_df = (\n",
    "    df.groupby(\"need_retrieval\", group_keys=False)\n",
    "    .apply(\n",
    "        lambda x: x.sample(num_samples_per_class, random_state=42), include_groups=True\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>prompt</th>\n",
       "      <th>need_retrieval</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>general_qa</td>\n",
       "      <td>What are the main disadvantages of electric ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Write like a noir detective: Adopt the gritty,...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brainstorming</td>\n",
       "      <td>What are the new 7 Wonders Cities:</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>information_extraction</td>\n",
       "      <td>Depict the valuation of Adani group as mention...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brainstorming</td>\n",
       "      <td>Give me a list of items I should bring to the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 category                                             prompt  \\\n",
       "0              general_qa  What are the main disadvantages of electric ca...   \n",
       "1                     NaN  Write like a noir detective: Adopt the gritty,...   \n",
       "2           brainstorming                What are the new 7 Wonders Cities:    \n",
       "3  information_extraction  Depict the valuation of Adani group as mention...   \n",
       "4           brainstorming  Give me a list of items I should bring to the ...   \n",
       "\n",
       "   need_retrieval title context answers  \n",
       "0               1   NaN     NaN     NaN  \n",
       "1               0   NaN     NaN     NaN  \n",
       "2               1   NaN     NaN     NaN  \n",
       "3               0   NaN     NaN     NaN  \n",
       "4               1   NaN     NaN     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(balanced_df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "\"bert-base-uncased is an effective model for understanding language patterns. \\\n",
    "Its Transformer architecture captures complex word relationships, and its uncased nature simplifies text processing. \\\n",
    "Widely supported and easy to fine-tune, it’s a strong choice for many NLP tasks.\n",
    "\n",
    "The authors of the article used BERT-basemultilingual-cased. \\\n",
    "I will use only English, therefore there is no need to use multilingual BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "\n",
    "def tokenize_data(df, tokenizer, max_length=512):\n",
    "    return tokenizer(\n",
    "        df[\"prompt\"].tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"bert-base-uncased\"\n",
    "num_labels = 2\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenize_data(train_df, tokenizer)\n",
    "val_encodings = tokenize_data(val_df, tokenizer)\n",
    "test_encodings = tokenize_data(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, indices):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        item[\"idx\"] = torch.tensor(self.indices[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_labels = train_df[\"need_retrieval\"].tolist()\n",
    "val_labels = val_df[\"need_retrieval\"].tolist()\n",
    "test_labels = test_df[\"need_retrieval\"].tolist()\n",
    "\n",
    "# saving the indices of specific samples in the dataset so that I can easily retrieve them later when needed\n",
    "train_indices = train_df.index.tolist()\n",
    "val_indices = val_df.index.tolist()\n",
    "test_indices = test_df.index.tolist()\n",
    "\n",
    "\n",
    "train_dataset = TextClassificationDataset(train_encodings, train_labels, train_indices)\n",
    "val_dataset = TextClassificationDataset(val_encodings, val_labels, val_indices)\n",
    "test_dataset = TextClassificationDataset(test_encodings, test_labels, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/micromamba/envs/spbrag/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, lr_scheduler, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_preds, train_labels = [], []\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if k != \"idx\"}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        train_preds.extend(preds.cpu().numpy())\n",
    "        train_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "    train_f1 = f1_score(train_labels, train_preds)\n",
    "\n",
    "    return avg_train_loss, train_accuracy, train_f1\n",
    "\n",
    "\n",
    "def validate_epoch(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != \"idx\"}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    val_f1 = f1_score(val_labels, val_preds)\n",
    "\n",
    "    return avg_val_loss, val_accuracy, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    lr_scheduler,\n",
    "    device,\n",
    "    num_epochs: int,\n",
    "    save_dir: str = \"./bert-text-classification-model\",\n",
    "    metric: str = \"f1\",\n",
    "    early_stopping_patience=None,\n",
    "):\n",
    "    best_val_metric = 0\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    metrics = {\n",
    "        \"train_losses\": [],\n",
    "        \"val_losses\": [],\n",
    "        \"train_accuracies\": [],\n",
    "        \"val_accuracies\": [],\n",
    "        \"train_f1_scores\": [],\n",
    "        \"val_f1_scores\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        logger.info(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        avg_train_loss, train_accuracy, train_f1 = train_epoch(\n",
    "            model, train_loader, optimizer, lr_scheduler, device\n",
    "        )\n",
    "        metrics[\"train_losses\"].append(avg_train_loss)\n",
    "        metrics[\"train_accuracies\"].append(train_accuracy)\n",
    "        metrics[\"train_f1_scores\"].append(train_f1)\n",
    "        logger.info(\n",
    "            f\"Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Training F1: {train_f1:.4f}\"\n",
    "        )\n",
    "\n",
    "        avg_val_loss, val_accuracy, val_f1 = validate_epoch(model, val_loader, device)\n",
    "        metrics[\"val_losses\"].append(avg_val_loss)\n",
    "        metrics[\"val_accuracies\"].append(val_accuracy)\n",
    "        metrics[\"val_f1_scores\"].append(val_f1)\n",
    "        logger.info(\n",
    "            f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Validation F1: {val_f1:.4f}\"\n",
    "        )\n",
    "\n",
    "        current_val_metric = val_f1 if metric == \"f1\" else val_accuracy\n",
    "\n",
    "        if current_val_metric > best_val_metric:\n",
    "            best_val_metric = current_val_metric\n",
    "            model.save_pretrained(save_dir)\n",
    "            logger.info(\n",
    "                f\"New best model saved with Validation {metric.capitalize()}: {best_val_metric:.4f}\"\n",
    "            )\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if (\n",
    "            early_stopping_patience\n",
    "            and epochs_without_improvement >= early_stopping_patience\n",
    "        ):\n",
    "            logger.info(f\"Early stopping at epoch {epoch + 1} due to no improvement.\")\n",
    "            break\n",
    "\n",
    "    logger.info(\n",
    "        f\"Loaded the best model with Validation {metric.capitalize()}: {best_val_metric:.4f}\"\n",
    "    )\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model,\n",
    "    test_loader,\n",
    "    test_df,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    test_results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            idxs = batch[\"idx\"].cpu().numpy()\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != \"idx\"}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=-1).cpu().numpy().tolist()\n",
    "            actual_labels = batch[\"labels\"].cpu().numpy().tolist()\n",
    "\n",
    "            texts = test_df.loc[idxs, \"prompt\"].tolist()\n",
    "            categories = test_df.loc[idxs, \"category\"].tolist()\n",
    "\n",
    "            test_results.extend(zip(texts, categories, actual_labels, preds))\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        test_results,\n",
    "        columns=[\"Text\", \"Category\", \"Need_retrieval\", \"Predicted\"],\n",
    "    )\n",
    "\n",
    "    logger.info(\"Test set evaluation completed.\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 23:09:34,109 - INFO - Test set evaluation completed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Need_retrieval</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do you play baseball</td>\n",
       "      <td>general_qa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In what area was Frédéric born in?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Change the text into a medieval speech Climate...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What types of political organizations did pre-...</td>\n",
       "      <td>closed_qa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the four largest British Virgin Islan...</td>\n",
       "      <td>open_qa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Category  \\\n",
       "0                          How do you play baseball   general_qa   \n",
       "1                 In what area was Frédéric born in?         NaN   \n",
       "2  Change the text into a medieval speech Climate...         NaN   \n",
       "3  What types of political organizations did pre-...   closed_qa   \n",
       "4  What are the four largest British Virgin Islan...     open_qa   \n",
       "\n",
       "   Need_retrieval  Predicted  \n",
       "0               1          1  \n",
       "1               1          1  \n",
       "2               0          0  \n",
       "3               0          0  \n",
       "4               1          1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = evaluate(\n",
    "    model=model, test_loader=test_loader, test_df=test_df, device=device\n",
    ")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    device=device,\n",
    "    num_epochs=4,\n",
    "    save_dir='./bert-text-classification-model',\n",
    "    metric=\"f1\",\n",
    "    early_stopping_patience=3,\n",
    ")\n",
    "\n",
    "\n",
    "train_losses = metrics[\"train_losses\"]\n",
    "val_losses = metrics[\"val_losses\"]\n",
    "train_f1_scores = metrics[\"train_f1_scores\"]\n",
    "val_f1_scores = metrics[\"val_f1_scores\"]\n",
    "train_accuracies = metrics[\"train_accuracies\"]\n",
    "val_accuracies = metrics[\"val_accuracies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(train_f1_scores, label='Training F1 Score')\n",
    "plt.plot(val_f1_scores, label='Validation F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Training and Validation F1 Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 23:09:57,597 - INFO - Test set evaluation completed.\n"
     ]
    }
   ],
   "source": [
    "results_df = evaluate(\n",
    "    model=model, test_loader=test_loader, test_df=test_df, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Need_retrieval</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do you play baseball</td>\n",
       "      <td>general_qa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In what area was Frédéric born in?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Change the text into a medieval speech Climate...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What types of political organizations did pre-...</td>\n",
       "      <td>closed_qa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the four largest British Virgin Islan...</td>\n",
       "      <td>open_qa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Category  \\\n",
       "0                          How do you play baseball   general_qa   \n",
       "1                 In what area was Frédéric born in?         NaN   \n",
       "2  Change the text into a medieval speech Climate...         NaN   \n",
       "3  What types of political organizations did pre-...   closed_qa   \n",
       "4  What are the four largest British Virgin Islan...     open_qa   \n",
       "\n",
       "   Need_retrieval  Predicted  \n",
       "0               1          1  \n",
       "1               1          1  \n",
       "2               0          0  \n",
       "3               0          0  \n",
       "4               1          1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"../data/predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            title  \\\n",
      "0  Sino-Tibetan_relations_during_the_Ming_dynasty   \n",
      "1                                             NaN   \n",
      "2                                             NaN   \n",
      "3                                         Beyoncé   \n",
      "4                         2008_Sichuan_earthquake   \n",
      "\n",
      "                                             context  \\\n",
      "0  Tsai writes that shortly after the visit by De...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  Her fourth studio album 4 was released on June...   \n",
      "4  In the China Digital Times an article reports ...   \n",
      "\n",
      "                                              prompt  \\\n",
      "0          What did Yongle want to trade with Tibet?   \n",
      "1  Extract the cinema industry and the percentage...   \n",
      "2  Adapt the text to make it relevant for a corpo...   \n",
      "3  What magazine did Beyoncé write a story for ab...   \n",
      "4           What did the China Digital Times report?   \n",
      "\n",
      "                                             answers  need_retrieval  \\\n",
      "0                              tea, horses, and salt               1   \n",
      "1                                                NaN               0   \n",
      "2                                                NaN               0   \n",
      "3                                            Essence               1   \n",
      "4  a close analysis by an alleged Chinese constru...               1   \n",
      "\n",
      "                 category  \n",
      "0                     NaN  \n",
      "1  information_extraction  \n",
      "2                     NaN  \n",
      "3                     NaN  \n",
      "4                     NaN  \n"
     ]
    }
   ],
   "source": [
    "test_df_2 = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "test_df_2 = test_df_2.rename(columns={\"question\": \"prompt\"})\n",
    "print(test_df_2.head())\n",
    "test_encodings_2 = tokenize_data(test_df_2, tokenizer)\n",
    "\n",
    "test_labels_2 = test_df_2[\"need_retrieval\"].tolist()\n",
    "\n",
    "# saving the indices of specific samples in the dataset so that I can easily retrieve them later when needed\n",
    "test_indices_2 = test_df_2.index.tolist()\n",
    "\n",
    "\n",
    "test_dataset_2 = TextClassificationDataset(\n",
    "    test_encodings_2, test_labels_2, test_indices_2\n",
    ")\n",
    "\n",
    "test_loader_2 = DataLoader(test_dataset_2, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.002303662709891796, 1.0, 1.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(model, test_loader_2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 23:11:31,466 - INFO - Test set evaluation completed.\n"
     ]
    }
   ],
   "source": [
    "results_df_2 = evaluate(\n",
    "    model=model, test_loader=test_loader_2, test_df=test_df_2, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Need_retrieval</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What did Yongle want to trade with Tibet?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extract the cinema industry and the percentage...</td>\n",
       "      <td>information_extraction</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adapt the text to make it relevant for a corpo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What magazine did Beyoncé write a story for ab...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What did the China Digital Times report?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Category  \\\n",
       "0          What did Yongle want to trade with Tibet?                     NaN   \n",
       "1  Extract the cinema industry and the percentage...  information_extraction   \n",
       "2  Adapt the text to make it relevant for a corpo...                     NaN   \n",
       "3  What magazine did Beyoncé write a story for ab...                     NaN   \n",
       "4           What did the China Digital Times report?                     NaN   \n",
       "\n",
       "   Need_retrieval  Predicted  \n",
       "0               1          1  \n",
       "1               0          0  \n",
       "2               0          0  \n",
       "3               1          1  \n",
       "4               1          1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
